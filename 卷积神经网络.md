 
# Padding（填补、填充）  
![3789d5fdfb07464ba1d3d24c52e163e6](https://user-images.githubusercontent.com/45502587/182561318-2e7b3850-6dac-41b1-8b22-8e9b44c7c3fe.gif)
## 原因  
卷积神经网络使用filter进行卷积操作时，对原始图片进行操作。但会带来以下几个问题：  
- 卷积运算后，输出图片的尺寸缩小；  
- 原始图片中越是边缘的像素点，对于输出的影响越小。因为卷积运算在移动过程中到边缘就结束了，中间部分的像素点参与多次计算，但是边缘像素点可能只参与一次，所以图片的边缘信息可能会丢失。  
## 作用  
为了解决上述问题，在深度学习的卷积操作中，对原始图片的边缘进行补0操作，即为padding。其作用在于：  
- 保持图片的边缘信息，在padding前，输入图片边缘的像素点信息只会被卷积核操作一次，padding操作后，增加了边缘像素点的计算次数，获取了更多的边缘信息。
- 使用padding可以输出图片和输入图片尺寸大小一致。  

## 卷积操作的类型
- 窄卷积（valid卷积）：生成的特征图比原始图像小。    
- 同卷积（same卷积）：与原始图大小一样。  
- 全卷积（full卷积）：也称反卷积，即把原始图片里的每个像素点都用卷积操作展开，可能会比原来的图片尺寸大。  

## Pytorch的Padding操作  
torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)   
![Pytorch函数说明](https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html#torch.nn.functional.conv2d)    
参数说明
- input – input tensor of shape (\text{minibatch} , \text{in\_channels} , iH , iW)(minibatch,in_channels,iH,iW)
- weight – filters of shape (\text{out\_channels} , \frac{\text{in\_channels}}{\text{groups}} , kH , kW)(out_channels, groups in_channels ,kH,kW)
- bias – optional bias tensor of shape (\text{out\_channels})(out_channels). Default: None
- stride – the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1
- padding – implicit paddings on both sides of the input. Can be a string {‘valid’, ‘same’}, single number or a tuple (padH, padW). Default: 0（填充0）. padding='valid' is the same as no padding. padding='same' pads the input so the output has the same shape as the input. However, this mode doesn’t support any stride values other than 1.
dilation – the spacing between kernel elements. Can be a single number or a tuple (dH, dW). Default: 1
groups – split input into groups, \text{in\_channels}in_channels should be divisible by the number of groups. Default: 1   

<font size = 3 > 卷积神经网络笔记 </font>  <font color="red">红色</font>
